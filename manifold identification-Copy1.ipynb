{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold Description Algorithms\n",
    "Pura Peetathawatchai (Poon)\n",
    "\n",
    "In this notebook, I have designed and implemented two different algorithms to identify, describe, and distinguish data manifolds in 3 dimensions.\n",
    "\n",
    "Both algorithms aim to capture 3 main attributes of a manifold: position, orientation and shape. \n",
    "\n",
    "The first section of the notebook contains code used to import the raw data, as well as the declaration of helper functions used for dimensional reduction. Dimensional reduction is applied to summarize each entry into three axes, labelled 0, 1, 2. \n",
    "\n",
    "Disclaimer: Other than the implementation of the \"Ellipsoid\" and \"Curved Plane\" algorithms, which are authored by me, I did not write all of this code; most of it has been imported from elsewhere.\n",
    "\n",
    "NOTE: The raw data used in this notebook is the property of EATLAB, and is therefore removed. Running this notebook will therefore result in an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import distance\n",
    "from scipy.optimize import minimize, curve_fit\n",
    "import scipy.integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExpander:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.functions = [\n",
    "            self.summation,\n",
    "            # self.subtractions,\n",
    "            self.division1,\n",
    "            self.division2,\n",
    "            self.multiplication,\n",
    "            self.sin,\n",
    "            self.cos\n",
    "        ]\n",
    "\n",
    "    def load(self,df):\n",
    "\n",
    "#         self.inputPath = inputPath\n",
    "#         df = pd.read_excel(self.inputPath, na_values=[' -','-'])\n",
    "        df = df.dropna(axis = 0)\n",
    "#         df = df.fillna(0)\n",
    "\n",
    "        self.df = copy.deepcopy(df)\n",
    "        ignores = ['Table_no','filename','sex','Product','Start Time','Stop Time','Total Time','Number of leftover',\n",
    "                   'Mix with other food','Avg movement magnitude','Total time in seconds','Total movement magnitude',\n",
    "                   'Score','index','Mix with other food regularised','Number of eat','menu_id','label','group','Cluster']\n",
    "\n",
    "        for ignore in ignores:\n",
    "            try:\n",
    "                del df[ignore]\n",
    "            except:\n",
    "                print(\"{} DNE\".format(ignore))\n",
    "        print(df.columns)\n",
    "        X = df.values\n",
    "        X = X - np.amin(X, axis=0)\n",
    "        X = (X/np.amax(X,axis=0))+1e-3\n",
    "\n",
    "        self.preprocessed = np.nan_to_num(X)\n",
    "\n",
    "        return self.preprocessed\n",
    "\n",
    "    def transform(self,itr=2):\n",
    "        X = self.preprocessed\n",
    "        self.expanded_data =np.array(list(\n",
    "            map(\n",
    "                self.expand,\n",
    "                X, np.ones(len(X)).astype(np.int) * itr\n",
    "            )\n",
    "        ))\n",
    "        return self.expanded_data\n",
    "\n",
    "    def save(self, outputPath):\n",
    "        print('DONE! {}'.format(outputPath))\n",
    "        print('shape: {}'.format(self.expanded_data.shape))\n",
    "        print('size: {}'.format(self.expanded_data.size))\n",
    "        print('total invalid values: {}'.format(np.count_nonzero(np.isnan(self.expanded_data))))\n",
    "\n",
    "    def expand(self,x,itr=2):\n",
    "        ret = list(x)\n",
    "        for i in range(itr):\n",
    "            out = []\n",
    "            for function_ in self.functions:\n",
    "                out = out + function_(ret)\n",
    "            ret= ret + out\n",
    "        return np.array(ret).astype(np.float32)\n",
    "\n",
    "    def default(self,x):\n",
    "        out = list(x)\n",
    "        return out\n",
    "\n",
    "    def summation(self,x):\n",
    "        x_list = list(x)\n",
    "        itr = len(x_list)-1\n",
    "        out = []\n",
    "        for x in range(itr):\n",
    "            first = x_list.pop(0)\n",
    "            out = out + list(np.array(x_list).astype(np.float32)+first)\n",
    "        return out\n",
    "\n",
    "    def subtractions(self,x):\n",
    "        x_list = list(x)\n",
    "        itr = len(x_list)-1\n",
    "        out = []\n",
    "        for x in range(itr):\n",
    "            first = x_list.pop(0)\n",
    "            out = out + list(np.array(x_list).astype(np.float32)-first)\n",
    "        return out+(out*-1)\n",
    "\n",
    "    def division1(self,x):\n",
    "        x_list = list(x)\n",
    "        itr = len(x_list)-1\n",
    "        out = []\n",
    "        for x in range(itr):\n",
    "            first = x_list.pop(0)\n",
    "            out = out + list(np.array(x_list).astype(np.float32)/(first))\n",
    "        return out\n",
    "\n",
    "    def division2(self, x):\n",
    "        x_list = list(x)\n",
    "        itr = len(x_list) - 1\n",
    "        out = []\n",
    "        for x in range(itr):\n",
    "            last = x_list.pop()\n",
    "            out = out + list(np.array(x_list).astype(np.float32) / last)\n",
    "        return out\n",
    "\n",
    "    def multiplication(self,x):\n",
    "        x_list = list(x)\n",
    "        itr = len(x_list)-1\n",
    "        out = []\n",
    "        for x in range(itr):\n",
    "            first = x_list.pop(0)\n",
    "            out = out + list(np.array(x_list).astype(np.float32)*first)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def sin(self,x):\n",
    "        return list(map(sp.sin, x))\n",
    "\n",
    "    def cos(self,x):\n",
    "        return list(map(sp.cos, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    def __exit__(self, exception_type, exception_value, traceback):\n",
    "        pass\n",
    "\n",
    "    def load_pkl(self,directory):\n",
    "        self.X = joblib.load(directory)[0].astype(np.float64)\n",
    "        self.X = (self.X-np.amin(self.X, axis=0))/(np.amax(self.X, axis=0)-np.amin(self.X, axis=0))\n",
    "        # self.Y = joblib.load(directory)[1]\n",
    "        self.df = joblib.load(directory)[1]\n",
    "        self.idx = np.array(range(0, self.X.shape[0]))\n",
    "        return {'X':self.X, 'df':self.df}\n",
    "    \n",
    "    def get_data(self,expanded_data,preprocessed_data):\n",
    "        self.X = expanded_data\n",
    "        self.X = (self.X-np.amin(self.X, axis=0))/(np.amax(self.X, axis=0)-np.amin(self.X, axis=0))\n",
    "        self.df = preprocessed_data\n",
    "        return self.X,self.df\n",
    "\n",
    "    def getStage1Transform(self):\n",
    "        return self.X_Stage1Embedding\n",
    "\n",
    "    def getStage2Transform(self):\n",
    "        return self.X_Stage2Embedding\n",
    "\n",
    "    def getStage3Transform(self):\n",
    "        return self.X_Stage3Embedding\n",
    "\n",
    "\n",
    "    def clustering(self,n_cluster):\n",
    "        self.n_cluster = n_cluster\n",
    "        cluster = self.X_Stage2Embedding\n",
    "        #kmeans = SpectralClustering(n_clusters= self.n_cluster,random_state=0,affinity=\"nearest_neighbors\").fit(cluster)\n",
    "        kmeans = KMeans(n_clusters=self.n_cluster, random_state= 0).fit(cluster)\n",
    "        cluster_number = kmeans.labels_\n",
    "        return cluster_number\n",
    "\n",
    "    def seperate_cluster(self,df_cluster):\n",
    "        cluster_ = []\n",
    "        for i in range(0,self.n_cluster):\n",
    "            cluster_.append(df_cluster[df_cluster['cluster']==i])\n",
    "        return cluster_\n",
    "\n",
    "    def compute_score(self,cluster_):\n",
    "        cluster_.drop(cluster_.columns[len(cluster_.columns) - 1], axis=1, inplace=True)\n",
    "        cluster_ = cluster_.values\n",
    "        eu_distance = euclidean_distances(cluster_, cluster_)\n",
    "        \n",
    "        index_0 = np.unravel_index(eu_distance.argmax(), eu_distance.shape)[0]\n",
    "        index_1 = np.unravel_index(eu_distance.argmax(), eu_distance.shape)[1]\n",
    "        index = [index_0,index_1]\n",
    "\n",
    "        max_point = cluster_[max(index)]\n",
    "        min_point = cluster_[min(index)]\n",
    "        vector_main = max_point - min_point\n",
    "\n",
    "        projected_cluster = []\n",
    "        for i in range(0, len(cluster_)):\n",
    "            vector_a = cluster_[i] - min_point\n",
    "            projected_cluster.append(\n",
    "                (min_point + np.dot(cluster_[i] - min_point, max_point - min_point) / \n",
    "                 np.dot(max_point - min_point, max_point - min_point) * (max_point - min_point)).tolist())\n",
    "        score_cluster = []\n",
    "        for i in range(0, len(cluster_)):\n",
    "            score_cluster.append(\n",
    "                round(distance.euclidean(min_point,projected_cluster[i]),6) / round(distance.euclidean(min_point,max_point),6))\n",
    "        return score_cluster,projected_cluster\n",
    "\n",
    "    def stage2transform(self, n_components=3):\n",
    "        X = self.X\n",
    "        X_Stage2Embedding = SpectralEmbedding(n_components=n_components, affinity='rbf', \n",
    "                                              random_state=0, eigen_solver=None).fit_transform(X)\n",
    "\n",
    "        self.X_Stage2Embedding =X_Stage2Embedding\n",
    "        return X_Stage2Embedding\n",
    "    \n",
    "    def curveFit2D(self,func, cluster_):\n",
    "        cluster_ = cluster_.values\n",
    "        X = cluster_[:,0]\n",
    "        Y = cluster_[:,1]\n",
    "\n",
    "        self.popt, self.pcov = curve_fit(func, X, Y)\n",
    "        return self.popt, self.pcov\n",
    "\n",
    "    def getCurve(self, func, cluster_):\n",
    "        cluster_ = cluster_.values\n",
    "        X2D = cluster_\n",
    "\n",
    "        x = np.sort(X2D[:,0])\n",
    "        y = func(np.sort(X2D[:,0]),*self.popt)\n",
    "        return np.column_stack((x,y))\n",
    "\n",
    "    def projectPointsToCurve(self, func, cluster_):\n",
    "\n",
    "        costfunc = lambda x, Xp, Yp: ((Xp-x)**2) + ((Yp-func(x,*self.popt))**2)\n",
    "        cluster_ = cluster_.values\n",
    "\n",
    "        X2D = cluster_\n",
    "\n",
    "        X = X2D[:,0]\n",
    "        Y = X2D[:,1]\n",
    "\n",
    "        Xhat = np.zeros(X.size)\n",
    "        Yhat = np.zeros(Y.size)\n",
    "\n",
    "        for i in range(0, X.size):\n",
    "            Xp = X[i]\n",
    "            Yp = Y[i]\n",
    "\n",
    "            Xhat[i] = minimize(costfunc, Xp, (Xp, Yp), method='CG').x\n",
    "            Yhat[i] = func(Xhat[i], *self.popt)\n",
    "\n",
    "        self.projected2D = np.column_stack((Xhat,Yhat))\n",
    "\n",
    "        return self.projected2D\n",
    "\n",
    "    def computeSatisfactionScale(self, func_prime):\n",
    "\n",
    "        lengthPath = lambda x: np.sqrt(1+func_prime(x, *self.popt)**2)\n",
    "\n",
    "        X2D = self.projected2D\n",
    "\n",
    "        X = X2D[:,0]\n",
    "        Y = X2D[:,1]\n",
    "\n",
    "        minX = np.amin(X)\n",
    "        maxX = np.amax(X)\n",
    "\n",
    "        self.totalLength = scipy.integrate.quad(lengthPath, minX, maxX)[0]\n",
    "\n",
    "        return self.totalLength\n",
    "\n",
    "    def computeSatisfactionScore(self, func_prime):\n",
    "\n",
    "        lengthPath = lambda x: np.sqrt(1+func_prime(x, *self.popt)**2)\n",
    "\n",
    "        X2D = self.projected2D\n",
    "\n",
    "        X = X2D[:,0]\n",
    "\n",
    "        score = np.zeros(X.shape)\n",
    "\n",
    "        minX = np.amin(X)\n",
    "\n",
    "        for i in range(0, X.size):\n",
    "            S = scipy.integrate.quad(lengthPath, minX, X[i])[0]\n",
    "            score[i] = S / self.totalLength\n",
    "\n",
    "        self.score = score\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, a, b):\n",
    "    return a*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_prime(x, a, b):\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(df,n_cluster,n_component):\n",
    "    dataExpander = DataExpander()\n",
    "    preprocessed_data = dataExpander.load(df)\n",
    "    expanded_data = dataExpander.transform(itr=2)\n",
    "    satisfactionModel = model()\n",
    "    get_data = satisfactionModel.get_data(expanded_data = expanded_data,preprocessed_data = preprocessed_data)\n",
    "    Stage2 = satisfactionModel.stage2transform(n_component)\n",
    "    cluster_number = satisfactionModel.clustering(n_cluster)\n",
    "    df_cluster = pd.DataFrame(Stage2)\n",
    "    df_cluster['cluster'] = cluster_number\n",
    "    cluster_ = satisfactionModel.seperate_cluster(df_cluster)\n",
    "    score = []\n",
    "    projected_2d = []\n",
    "    for i in range(0,len(cluster_)):\n",
    "        score_,projected2d_ = satisfactionModel.compute_score(cluster_[i])\n",
    "#         popt, pcov = satisfactionModel.curveFit2D(func,cluster_[i])\n",
    "#         fittedcurve = satisfactionModel.getCurve(func,cluster_[i])\n",
    "#         projected2d_ = satisfactionModel.projectPointsToCurve(func,cluster_[i])\n",
    "#         totalLength = satisfactionModel.computeSatisfactionScale(func_prime)\n",
    "#         score_ = satisfactionModel.computeSatisfactionScore(func_prime)\n",
    "        score = np.append(score, score_)\n",
    "        projected_2d.append(projected2d_)\n",
    "        \n",
    "    concatCluster = pd.concat(cluster_)\n",
    "    concatCluster['score'] = score\n",
    "    concatCluster = concatCluster.sort_index()\n",
    "    df = dataExpander.df\n",
    "    for i in range(0,n_component):\n",
    "        df[i]=Stage2[:,i]\n",
    "#     df['x']=Stage2[:,0]\n",
    "#     df['y']=Stage2[:,1]\n",
    "#     df['z']=Stage2[:,2]\n",
    "    df['cluster'] = cluster_number\n",
    "    df['Score'] = concatCluster['score']\n",
    "    return df, Stage2,projected_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0d691a9631c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import plotly.io as plio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_notebook_mode(connected=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we import the raw data. Replace the file path with the equilvalent file in the case that the code fails at this point. \n",
    "\n",
    "NOTE: Data used in internship removed since it is the property of EATLAB. This program will therefore raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('REMOVED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = pd.DataFrame()\n",
    "for cat in ['food','coffee','late','tea','desert','appetizer']:\n",
    "    table_id = pd.concat([table_id,pd.read_excel('/Users/Pura 1/Documents/EATLAB Internship/Table_Menu_ID.xlsx',dtype=str,sheet_name=cat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = table_id.rename(columns={'menu_th':'Product'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = table_id.drop_duplicates(subset='Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_cluster = pd.read_csv('/Users/Pura 1/Documents/EATLAB Internship/Clustering (1)',converters={'menu_id':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df,table_id[['Product','menu_id']],on='Product',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df,food_cluster[['Product','Cluster']],on='Product',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we clean the data using the Grubb's test for outliers in a normal distribution. I have chosen to apply the test to variables which are shown to have a distribution similar to a normal distribution and filter out any outliers. This should improve the quality of the raw data and improve the performance of the manifold description algorithms. \n",
    "\n",
    "Note: However, I have failed to find an effective way to test for variables with distributions similar to reciprocal or inverse exponential probability distributions. The application of a one tailed Grubb's test (treating the inverse distribution as a ~N(0, mean^2) has resulted in a number of type 2 errors in identifying outliers. Thus, data has not been cleaned for variables/columns with such distributions. \n",
    "\n",
    "(See \"Data Cleaning\" file for more information on the distribution) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outliers import smirnov_grubbs as grubbs\n",
    "\n",
    "df= df[df['No. of bite'] < np.array(grubbs.max_test_outliers(df['No. of bite'], alpha= 0.05)).min()]\n",
    "df= df[df['Avg movement magnitude'] < np.array(grubbs.max_test_outliers(df['Avg movement magnitude'], alpha= 0.05)).min()]\n",
    "df= df[df['Total movement magnitude'] < np.array(grubbs.max_test_outliers(df['Total movement magnitude'], alpha= 0.05)).min()]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensional reduction is applied here. A choice between k-means and spectral clustering is applied to group the projected data points to its respective clusters. The choice of whether to use k-means or spectral clustering can be changed at In[4] at the definition of the \"clustering\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ = df\n",
    "df_ = df_.reset_index(drop=True)\n",
    "result, Stage2, projected2D = compute(df=df_,n_cluster=4,n_component=3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d(data,c1):\n",
    "    trace = go.Scatter(\n",
    "        x = data[:,0],\n",
    "        y = data[:,1],\n",
    "        mode = 'markers',\n",
    "        marker=dict(size=4, color=c1, line=dict(color='black', width=0.5), opacity=0.8)\n",
    "    )\n",
    "    axis = dict(\n",
    "        showbackground=True, # show axis background\n",
    "        backgroundcolor=\"rgb(204, 204, 204)\", # set background color to grey\n",
    "        gridcolor=\"rgb(255, 255, 255)\",       # set grid line color\n",
    "        zerolinecolor=\"rgb(255, 255, 255)\",   # set zero grid line color\n",
    "    )\n",
    "    data_test1 = go.Data([trace])\n",
    "    # Make a layout object\n",
    "    layout = go.Layout(\n",
    "        title='Manifold', # set plot title\n",
    "        scene=go.Scene(  # axes are part of a 'scene' in 3d plots\n",
    "            xaxis=go.XAxis(axis), # set x-axis style\n",
    "            yaxis=go.YAxis(axis)\n",
    "        ),\n",
    "        yaxis = dict(),\n",
    "        xaxis = dict(range = [-0.01,0.01],scaleanchor = \"y\")\n",
    "    )\n",
    "    fig = go.Figure(data=data_test1, layout=layout)\n",
    "    iplot(fig, filename='test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_projected2d(data):\n",
    "    data1 = data[0]\n",
    "    data2 = data[1]\n",
    "    trace1 = go.Scatter(\n",
    "        x = data1[:,0],\n",
    "        y = data1[:,1],\n",
    "        mode = 'markers',\n",
    "        marker=dict(size=4, line=dict(color='black', width=0.5), opacity=0.8)\n",
    "    )\n",
    "    trace2 = go.Scatter(\n",
    "        x = data2[:,0],\n",
    "        y = data2[:,1],\n",
    "        mode = 'markers',\n",
    "        marker=dict(size=4, line=dict(color='black', width=0.5), opacity=0.8)\n",
    "    )\n",
    "    axis = dict(\n",
    "        showbackground=True, # show axis background\n",
    "        backgroundcolor=\"rgb(204, 204, 204)\", # set background color to grey\n",
    "        gridcolor=\"rgb(255, 255, 255)\",       # set grid line color\n",
    "        zerolinecolor=\"rgb(255, 255, 255)\",   # set zero grid line color\n",
    "    )\n",
    "    data_test1 = go.Data([trace1,trace2])\n",
    "    # Make a layout object\n",
    "    layout = go.Layout(\n",
    "        title='Manifold', # set plot title\n",
    "        scene=go.Scene(  # axes are part of a 'scene' in 3d plots\n",
    "            xaxis=go.XAxis(axis), # set x-axis style\n",
    "            yaxis=go.YAxis(axis)\n",
    "        ),\n",
    "        yaxis = dict(),\n",
    "        xaxis = dict(range = [-0.01,0.01],scaleanchor = \"y\")\n",
    "    )\n",
    "    fig = go.Figure(data=data_test1, layout=layout)\n",
    "    iplot(fig, filename='test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_score(df,cluster_no,label):\n",
    "    df_ = df.copy()\n",
    "    df_['Score'][(df_['cluster'] == cluster_no)&(df_['label'] == label)] = 1 - df_['Score'][(df_['cluster'] == cluster_no)&(df_['label'] == label)]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A visualization of the data is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = []\n",
    "for i in [0, 1, 2, 3]:\n",
    "    trace.append(go.Scatter3d(\n",
    "    x=np.array(result[0][result['cluster']==i]),\n",
    "    y=np.array(result[1][result['cluster']==i]),\n",
    "    z=np.array(result[2][result['cluster']==i]),\n",
    "    mode='markers',\n",
    "    marker=dict(size=4, line=dict(width=0.5), opacity=0.8),\n",
    "    name= i,\n",
    "    text = [i],\n",
    "    textposition='bottom center')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test1 = go.Data(trace)\n",
    "\n",
    "# Dictionary of style options for all axes\n",
    "axis = dict(\n",
    "    showbackground=True, # show axis background\n",
    "    backgroundcolor=\"rgb(204, 204, 204)\", # set background color to grey\n",
    "    gridcolor=\"rgb(255, 255, 255)\",       # set grid line color\n",
    "    zerolinecolor=\"rgb(255, 255, 255)\",   # set zero grid line color\n",
    ")\n",
    "\n",
    "# Make a layout object\n",
    "layout = go.Layout(showlegend=True,\n",
    "    title='Manifold', # set plot title\n",
    "    scene=go.Scene(  # axes are part of a 'scene' in 3d plots\n",
    "        xaxis=go.XAxis(axis), # set x-axis style\n",
    "        yaxis=go.YAxis(axis), # set y-axis style\n",
    "        zaxis=go.ZAxis(axis)),  # set z-axis style\n",
    "\n",
    ")\n",
    "\n",
    "# Make a figure object\n",
    "fig = go.Figure(data=data_test1, layout=layout)\n",
    "iplot(fig, filename='test1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ellipsoid Algorithm\n",
    "Pura Peetathawatchai (Poon)\n",
    "\n",
    "The algorithm is reccommended for use in data clusters with ellipsoid-like shape, similar to the ones in the visualization above. Ellipsoid-like shapes also include rods, cloud-like clusters, or even banana-like shapes. \n",
    "\n",
    "The algorithm takes in a 2-dimensional np.array as input. This 2-dimensional array is a list of points (each point a coordinate in the form of a 3-element list). A function toManifoldList is provided to extract such an array from the csv file containing the raw data. Should an error occur in this function, examine the DataFrame with the coordinates of the dimensional reduced points and edit the function definition to extract the appropriate columns through indexing.\n",
    "\n",
    "The position of the manifold is described using a centroid (x) of all the data points in the manifold. The orientation and shape of the manifold is described using 6 axial vectors, (v_1, ..., v_6). The vectors v_1 and v_2 describe the principal axis of the ellipsoid like manifold. Vectors v_3, v_4 describe the main axis of the cross section, while v_5 and v_6 describe the secondary axis of the cross section. Together, the 6 vectors stemming from the centroid create a skeleton of the manifold's structure.\n",
    "\n",
    "However, the function returns (x_1, ... x_6) where x_i = x + v_i for i in 1..6. This is so that we can utilize the scatterplotting functionality of plotly to see the terminal points for the v_i. However, v_i can easily be obtained from x_i using v_i = x_i - x.\n",
    "\n",
    "To account for outliers, instead of using a single furthermost point in a particular direction as a basis for calculating v_i, we use the furthermost 5% of points for such calculation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Converts the table to a manifoldList format: a nested list, with each entry a point in the manifold. \n",
    "def toManifoldList(result):\n",
    "    L= []\n",
    "    array= np.array([result[0], result[1], result[2]]) # Replace with column headers / indices of appropriate df columns\n",
    "    size= array[0].size\n",
    "    for i in range(size):\n",
    "        x= array[0][i]\n",
    "        y= array[1][i]\n",
    "        z= array[2][i]\n",
    "        L.append([x, y, z])\n",
    "        \n",
    "    return np.array(L)\n",
    "\n",
    "\n",
    "# MAIN ALGORITHM\n",
    "def ellipsoid(manifold):\n",
    "    x= centroid(manifold)\n",
    "    tip= findTip(manifold, x, 0.1)\n",
    "    mean_dist= dist(centroid(tip), x)\n",
    "    min_tip_dist= tip[tip[:,3].argsort()][0][3]\n",
    "    \n",
    "    if min_tip_dist > mean_dist:\n",
    "        kmeans= KMeans(n_clusters= 2)\n",
    "        kmeans.fit(tip)\n",
    "        y_kmeans= kmeans.predict(tip)\n",
    "        tip_cluster= np.append(tip, np.transpose([y_kmeans]), axis= 1)\n",
    "        x1= tip_cluster[tip_cluster[:,4] == 0].mean(axis= 0)\n",
    "        x2= tip_cluster[tip_cluster[:,4] == 1].mean(axis= 0)\n",
    "    else:\n",
    "        tip= findTip(manifold, x, 0.05)\n",
    "        x1= tip.mean(axis= 0)[0:3]\n",
    "        filtered= filter(manifold, x1 - x, x)\n",
    "        tip2= findTip(filtered, x, 0.1)\n",
    "        x2= tip2.mean(axis= 0)[0:3]\n",
    "    \n",
    "    projection= []\n",
    "    p_axis= x1 - x2\n",
    "    for point in manifold:\n",
    "        projection.append(projPlane(point, p_axis, x).tolist())\n",
    "    projection= np.array(projection)\n",
    "    \n",
    "    tip= findTip(projection, x, 0.1)\n",
    "    mean_dist= dist(centroid(tip), x)\n",
    "    min_tip_dist= tip[tip[:,3].argsort()][0][3]\n",
    "    \n",
    "    if min_tip_dist > mean_dist:\n",
    "        kmeans= KMeans(n_clusters= 2)\n",
    "        kmeans.fit(tip)\n",
    "        y_kmeans= kmeans.predict(tip)\n",
    "        tip_cluster= np.append(tip, np.transpose([y_kmeans]), axis= 1)\n",
    "        x3= tip_cluster[tip_cluster[:,4] == 0].mean(axis= 0)\n",
    "        x4= tip_cluster[tip_cluster[:,4] == 1].mean(axis= 0)\n",
    "    else:\n",
    "        tip= findTip(projection, x, 0.05)\n",
    "        x3= tip.mean(axis= 0)[0:3]\n",
    "        filtered= filter(projection, x3 - x, x)\n",
    "        tip2= findTip(filtered, x, 0.1)\n",
    "        x4= tip2.mean(axis= 0)[0:3]\n",
    "        \n",
    "    projection2= []\n",
    "    s_axis= x3 - x4\n",
    "    for point in projection:\n",
    "        projection2.append(projPlane(point, s_axis, x).tolist())\n",
    "    projection2= np.array(projection2)\n",
    "    \n",
    "    tip= findTip(projection2, x, 0.1)\n",
    "    mean_dist= dist(centroid(tip), x)\n",
    "    min_tip_dist= tip[tip[:,3].argsort()][0][3]\n",
    "    \n",
    "    if min_tip_dist > mean_dist:\n",
    "        kmeans= KMeans(n_clusters= 2)\n",
    "        kmeans.fit(tip)\n",
    "        y_kmeans= kmeans.predict(tip)\n",
    "        tip_cluster= np.append(tip, np.transpose([y_kmeans]), axis= 1)\n",
    "        x5= tip_cluster[tip_cluster[:,4] == 0].mean(axis= 0)\n",
    "        x6= tip_cluster[tip_cluster[:,4] == 1].mean(axis= 0)\n",
    "    else:\n",
    "        tip= findTip(projection2, x, 0.05)\n",
    "        x5= tip.mean(axis= 0)[0:3]\n",
    "        filtered= filter(projection2, x5 - x, x)\n",
    "        tip2= findTip(filtered, x, 0.1)\n",
    "        x6= tip2.mean(axis= 0)[0:3]\n",
    "        \n",
    "    return [x[0:3].tolist(), x1[0:3].tolist(), x2[0:3].tolist(), x3[0:3].tolist(), x4[0:3].tolist(), x5[0:3].tolist(), x6[0:3].tolist()]\n",
    "\n",
    "\n",
    "# Calculate the centroid of a set of points.\n",
    "# Precondition: manifold is a manifoldList\n",
    "def centroid(manifold):\n",
    "    sum= [0, 0, 0]\n",
    "    for p in manifold:\n",
    "        sum[0]= sum[0] + p[0]\n",
    "        sum[1]= sum[1] + p[1]\n",
    "        sum[2]= sum[2] + p[2]\n",
    "    \n",
    "    return np.array(sum) / size(manifold)\n",
    "\n",
    "\n",
    "# Return the number of points in the data_set\n",
    "# Precondition: data_set is not empty and is a manifoldList\n",
    "def size(data_set):\n",
    "    return data_set.size // data_set[0].size\n",
    "\n",
    "\n",
    "# Find the furtherest p points from the centroid in the data_set. Adds a distance to centroid attribute to each point.\n",
    "# Precondition: p in [0, 1], data set is a manifoldList\n",
    "def findTip(data_set, centroid, p):\n",
    "    matrix= data_set.tolist()\n",
    "    for i in range(size(data_set)):\n",
    "        point= matrix[i]\n",
    "        point.append(dist(point, centroid))\n",
    "    \n",
    "    dataSet= np.array(matrix)\n",
    "    dataSet= dataSet[dataSet[:,3].argsort()]\n",
    "    tip= dataSet[-round(p*size(data_set)):]\n",
    "    \n",
    "    return tip\n",
    "\n",
    "\n",
    "# Find the distance between 2 points in co-ordinate representation\n",
    "def dist(point1, point2):\n",
    "    return math.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2 + (point1[2] - point2[2])**2)\n",
    "\n",
    "\n",
    "# Project point onto a 2-Dimensional plane defined by a pivot and a normal vector. \n",
    "# The pivot is any given point on the plane.\n",
    "# Precondition: entries are np.arrray\n",
    "def projPlane(point, normal, pivot):\n",
    "    return point - projLine(point, normal, pivot) + pivot\n",
    "\n",
    "\n",
    "# Project point onto a 2-Dimensional plane defined by a pivot and a normal vector. \n",
    "# The pivot is any given point on the plane.\n",
    "# Precondition: entries are np.array\n",
    "def projLine(point, line, pivot):\n",
    "    point= point[0:3]\n",
    "    line= line[0:3]\n",
    "    pivot= pivot[0:3]\n",
    "    \n",
    "    proj_v= np.dot(point - pivot, line) / (line[0]**2 + line[1]**2 + line[2]**2) * np.array(line)\n",
    "    return proj_v + pivot\n",
    "\n",
    "\n",
    "# Filter for points which, when projected to the vector, have a negative coefficient. \n",
    "# Vector is a directional vector not a positional vector. \n",
    "def filter(data_set, vector, pivot):\n",
    "    filtered= []\n",
    "    for point in data_set:\n",
    "        if ((projLine(point, vector, pivot) - pivot) / vector)[0] < 0:\n",
    "            filtered.append(point.tolist())\n",
    "            \n",
    "    return np.array(filtered)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the algorithm output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifold= toManifoldList(result[result['cluster'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trace = []\n",
    "trace.append(go.Scatter3d(\n",
    "x=np.array(manifold[:,0]),\n",
    "y=np.array(manifold[:,1]),\n",
    "z=np.array(manifold[:,2]),\n",
    "mode='markers',\n",
    "marker=dict(size=4, line=dict(width=0.5), opacity=0.8),\n",
    "name= 0,\n",
    "text = [0],\n",
    "textposition='bottom center')\n",
    "                )\n",
    "skeleton= ellipsoid(manifold)\n",
    "#skeleton.append(x + p_axis)\n",
    "skeleton= np.array(skeleton)\n",
    "trace.append(go.Scatter3d(\n",
    "x=np.array(skeleton[:,0]),\n",
    "y=np.array(skeleton[:,1]),\n",
    "z=np.array(skeleton[:,2]),\n",
    "mode='markers',\n",
    "marker=dict(size=4, line=dict(width=0.5), opacity=0.8),\n",
    "name= 3,\n",
    "text = [3],\n",
    "textposition='bottom center')\n",
    "                )\n",
    "data_test3 = go.Data(trace)\n",
    "\n",
    "# Dictionary of style options for all axes\n",
    "axis = dict(\n",
    "    showbackground=True, # show axis background\n",
    "    backgroundcolor=\"rgb(204, 204, 204)\", # set background color to grey\n",
    "    gridcolor=\"rgb(255, 255, 255)\",       # set grid line color\n",
    "    zerolinecolor=\"rgb(255, 255, 255)\",   # set zero grid line color\n",
    ")\n",
    "\n",
    "# Make a layout object\n",
    "layout = go.Layout(showlegend=True,\n",
    "    title='Manifold', # set plot title\n",
    "    scene=go.Scene(  # axes are part of a 'scene' in 3d plots\n",
    "        xaxis=go.XAxis(axis), # set x-axis style\n",
    "        yaxis=go.YAxis(axis), # set y-axis style\n",
    "        zaxis=go.ZAxis(axis)),  # set z-axis style\n",
    "\n",
    ")\n",
    "\n",
    "# Make a figure object\n",
    "fig = go.Figure(data=data_test3, layout=layout)\n",
    "iplot(fig, filename='test3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curved Surface Algorithm\n",
    "Pura Peetathawatchai (Poon)\n",
    "\n",
    "This algorithm is reccommended for use in data manifolds which take the form of a curved surface or terrain.\n",
    "\n",
    "The algorithm takes in the raw DataFrame containing the dimensionality reduced axes. It converts this to another DataFrame using the toManifoldDF function. Should an error occur in this function, examine the DataFrame with the coordinates of the dimensional reduced points and edit the function definition to extract the appropriate columns through indexing.\n",
    "\n",
    "The model draws inspiration from Bezier Surfaces. It first conducts multivariable linear regression then orthogonally projects a copy of all the points onto a flat 2-dimensional plane. It then finds a minimum bounding rectangle for the projection, and divides it into AXIS_TILES^2 tiles. Each tile stores information on the mean orthogonal residual of all the points which are projected on the tile. This gives information on the shape of the curved surface. Tiles which have no points projected onto them are treated as empty. \n",
    "\n",
    "The position can be given by the midpoint of the mimimum bounding rectangle (midpoint), while the orientation can be given by the normal vector to the flat plane (normal). For visualization purposes, they are not returned by the function, but the return statement can be edited accordingly to yield the values of said variables.\n",
    "\n",
    "However, a weakness of this algorithm is it's sensitivity to outliers, so input data should be cleaned to an extent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AXIS_TILES = 5 # Algorithm will divide section into n^2 tiles\n",
    "\n",
    "from sklearn import linear_model\n",
    "from numpy import linalg as LA\n",
    "import sys  # maxint\n",
    "\n",
    "def toManifoldDF(result):\n",
    "    return pd.DataFrame({'x': result[0], 'y': result[1], 'z': result[2]}) # Set index to corresponding col names in DataFrame\n",
    "\n",
    "# MAIN ALGORITHM\n",
    "def plane(result):\n",
    "    print(\"OK\")\n",
    "    df= toManifoldDF(result)\n",
    "    manifold= toManifoldList(result)\n",
    "    \n",
    "    X= df[['x', 'y']]\n",
    "    Y= df['z']\n",
    "    regr= linear_model.LinearRegression()\n",
    "    regr.fit(X, Y)\n",
    "    main_axis= 'z'\n",
    "    normal= [regr.coef_[0], regr.coef_[1], -1.0]\n",
    "    intercept= [0.0, 0.0, regr.intercept_]\n",
    "    \n",
    "    maxCoef= max(math.fabs(regr.coef_[0]), math.fabs(regr.coef_[1]), 1.0)\n",
    "    \n",
    "    if maxCoef == regr.coef_[0]:\n",
    "        X= df[['y', 'z']]\n",
    "        Y= df['x']\n",
    "        regr.fit(X, Y)\n",
    "        main_axis= 'x'\n",
    "        intercept= [regr.intercept_, 0.0, 0.0]\n",
    "        normal= [-1.0, regr.coef_[0], regr.coef_[1]]\n",
    "    elif maxCoef == regr.coef_[1]:\n",
    "        X= df[['x', 'z']]\n",
    "        Y= df['y']\n",
    "        regr.fit(X, Y)\n",
    "        main_axis= 'y'\n",
    "        normal= [regr.coef_[0], -1.0, regr.coef_[1]]\n",
    "        intercept= [0.0, regr.intercept_, 0.0] \n",
    "        \n",
    "    projection= []\n",
    "    projDict= {}\n",
    "        \n",
    "    for point in manifold:\n",
    "        projected= projPlane(point, normal, intercept).tolist()\n",
    "        projDict[tuple(point.tolist())]= projected\n",
    "        projection.append(projected)\n",
    "    \n",
    "    encoded= encode(projection, main_axis,intercept)\n",
    "    convexHull= GrahamScan(encoded).tolist()\n",
    "    convexHull.append(convexHull[0])\n",
    "    convexHull= np.array(convexHull)\n",
    "    boundingBox= minBoundingRect(convexHull)\n",
    "    boundingBox= decode(boundingBox, main_axis, regr)\n",
    "    \n",
    "    corner= boundingBox[1]\n",
    "    M= maxNorm(boundingBox[0] - corner, boundingBox[2] - corner)\n",
    "    m= minNorm(boundingBox[0] - corner, boundingBox[2] - corner)\n",
    "    \n",
    "    midpoint= (boundingBox[0] + boundingBox[1] + boundingBox[2] + boundingBox[3]) / 4\n",
    "    \n",
    "    tile_matrix= []\n",
    "    \n",
    "    for i in range(AXIS_TILES):\n",
    "        row= []\n",
    "        for j in range(AXIS_TILES):\n",
    "            center= corner + (i + 0.5) * M / AXIS_TILES + (j + 0.5) * m / AXIS_TILES\n",
    "            tile= Tile(i, j, center)\n",
    "            row.append(tile)\n",
    "        tile_matrix.append(row)\n",
    "    \n",
    "    for point in manifold:\n",
    "        projected= projDict[tuple(point.tolist())]\n",
    "        sltn= decompose(projected - corner, M, m)\n",
    "        M_coef= sltn[0]\n",
    "        m_coef= sltn[1]\n",
    "        \n",
    "        i= int(M_coef * AXIS_TILES)\n",
    "        j= int(m_coef * AXIS_TILES)\n",
    "        tile_matrix[i][j].add(point, projected)\n",
    "            \n",
    "    outList= []\n",
    "    for i in range(AXIS_TILES):\n",
    "        for j in range(AXIS_TILES):\n",
    "            print(tile_matrix[i][j])\n",
    "            if tile_matrix[i][j].getSize() != 0:\n",
    "                point= tile_matrix[i][j].getCenter() + tile_matrix[i][j].getR()\n",
    "                outList.append(point.tolist())\n",
    "    \n",
    "    return np.array(outList)\n",
    "    \n",
    "# Maps projected point to a 2-dimensional Euclidian space so that the minimum bounding rectangle algorithm can be \n",
    "# applied. \n",
    "def encode(projection, main_axis, intercept):\n",
    "    encoded= []\n",
    "    \n",
    "    for point in projection:\n",
    "        projected2= projPlane(np.array(point), np.array(intercept), np.array([0, 0, 0])).tolist()\n",
    "        \n",
    "        if main_axis == 'x':\n",
    "            encoded.append([projected2[1], projected2[2]])\n",
    "        elif main_axis == 'y':\n",
    "            encoded.append([projected2[0], projected2[2]])\n",
    "        else:\n",
    "            encoded.append([projected2[0], projected2[1]])\n",
    "    \n",
    "    return encoded\n",
    "\n",
    "# Maps point in 2-dimensional Euclidean space back into 3-dimensional Euclidean space. \n",
    "def decode(coordinates, main_axis, regr):\n",
    "    decoded= []\n",
    "    memory= regr.predict(pd.DataFrame(coordinates))\n",
    "    \n",
    "    for i in range(size(coordinates)):\n",
    "        if main_axis == 'x':\n",
    "            point= [memory[i], coordinates[i][0], coordinates[i][1]]\n",
    "        elif main_axis == 'y':\n",
    "            point= [coordinates[i][0], memory[i], coordinates[i][1]]\n",
    "        else:\n",
    "            point= [coordinates[i][0], coordinates[i][1], memory[i]]\n",
    "        decoded.append(point)\n",
    "    \n",
    "    return np.array(decoded)\n",
    "\n",
    "# Return point is contained in rectangle\n",
    "# Rectangle is a np.array of 4 co-ordinates. Precondition: adjacent entries in rectangle are also geometrically \n",
    "# adjacent\n",
    "def contained(point, rectangle):\n",
    "    M= max()\n",
    "\n",
    "# Calculates the perpendicular distance between point3 and a line passing through point1 and point2.\n",
    "# Precondition: all entries are np.array\n",
    "def normalDist(point1, point2, point3):\n",
    "    return np.norm(np.cross((point2 - point1), (point1 - point3))) / np.norm(point2 - point1)\n",
    "\n",
    "def maxNorm(vector1, vector2):\n",
    "    return vector1 if LA.norm(vector1) > LA.norm(vector2) else vector2\n",
    "\n",
    "def minNorm(vector1, vector2):\n",
    "    return vector1 if LA.norm(vector1) < LA.norm(vector2) else vector2\n",
    "\n",
    "# Express vector as a linear combination of base1 and base2\n",
    "# Precondition: base1 and base2 are independent np.array and vector is in span(base1, base2)\n",
    "def decompose(vector, base1, base2):\n",
    "    A= np.array([base1.tolist(), base2.tolist(), np.cross(base1, base2).tolist()])\n",
    "    A= np.transpose(A)\n",
    "    b= vector\n",
    "    \n",
    "    return np.linalg.solve(A, b)\n",
    "\n",
    "\n",
    "# Represents a tile (aka sub-rectangle) on the minimum bounding rectangle\n",
    "class Tile(object):\n",
    "    def __init__(self, MID, mID, center):\n",
    "        self._MID= MID\n",
    "        self._mID= mID\n",
    "        self._points= []\n",
    "        self._center= center\n",
    "        self._size= 0\n",
    "        self._r= 0\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if self._size == 0:\n",
    "            return \"empty tile, ID: \" + str(self._MID) + str(self._mID)\n",
    "        \n",
    "        return \"Tile ID: \" + str(self._MID) + str(self._mID) + \" size: \" + str(self._size) + \" r: \" + str(self._r)\n",
    "\n",
    "    def getSize(self):\n",
    "        return self._size\n",
    "    \n",
    "    def getCenter(self):\n",
    "        return self._center\n",
    "    \n",
    "    def add(self, point, projection):\n",
    "        self._points.append(point)\n",
    "        self._r= (self._r * self._size + (point - projection)) / (self._size + 1)\n",
    "        self._size= self._size + 1\n",
    "        \n",
    "    def getR(self):\n",
    "        return self._r\n",
    "    \n",
    "\n",
    "# Function to know if we have a CCW turn\n",
    "# Author: Rodolfo Ferro (ferro@cimat.mx)\n",
    "def RightTurn(p1, p2, p3):\n",
    "    if (p3[1]-p1[1])*(p2[0]-p1[0]) >= (p2[1]-p1[1])*(p3[0]-p1[0]):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Author: Rodolfo Ferro (ferro@cimat.mx)\n",
    "def GrahamScan(P):\n",
    "    P.sort() # Sort the set of points\n",
    "    L_upper = [P[0], P[1]] # Initialize upper part\n",
    "    # Compute the upper part of the hull\n",
    "    for i in range(2,len(P)):\n",
    "        L_upper.append(P[i])\n",
    "        while len(L_upper) > 2 and not RightTurn(L_upper[-1],L_upper[-2],L_upper[-3]):\n",
    "            del L_upper[-2]\n",
    "    L_lower = [P[-1], P[-2]] # Initialize the lower part\n",
    "    # Compute the lower part of the hull\n",
    "    for i in range(len(P)-3,-1,-1):\n",
    "        L_lower.append(P[i])\n",
    "        while len(L_lower) > 2 and not RightTurn(L_lower[-1],L_lower[-2],L_lower[-3]):\n",
    "            del L_lower[-2]\n",
    "    del L_lower[0]\n",
    "    del L_lower[-1]\n",
    "    L = L_upper + L_lower # Build the full hull\n",
    "    print(np.array(L))\n",
    "    return np.array(L)\n",
    "\n",
    "# Copyright (c) 2013, David Butterworth, University of Queensland\n",
    "# All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#     * Redistributions of source code must retain the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer.\n",
    "#     * Redistributions in binary form must reproduce the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer in the\n",
    "#       documentation and/or other materials provided with the distribution.\n",
    "#     * Neither the name of the Willow Garage, Inc. nor the names of its\n",
    "#       contributors may be used to endorse or promote products derived from\n",
    "#       this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n",
    "# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "# POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "def minBoundingRect(hull_points_2d):\n",
    "    #print \"Input convex hull points: \"\n",
    "    #print hull_points_2d\n",
    "\n",
    "    # Compute edges (x2-x1,y2-y1)\n",
    "    edges = np.zeros( (len(hull_points_2d)-1,2) ) # empty 2 column array\n",
    "    for i in range( len(edges) ):\n",
    "        edge_x = hull_points_2d[i+1,0] - hull_points_2d[i,0]\n",
    "        edge_y = hull_points_2d[i+1,1] - hull_points_2d[i,1]\n",
    "        edges[i] = [edge_x,edge_y]\n",
    "    #print \"Edges: \\n\", edges\n",
    "\n",
    "    # Calculate edge angles   atan2(y/x)\n",
    "    edge_angles = np.zeros( (len(edges)) ) # empty 1 column array\n",
    "    for i in range( len(edge_angles) ):\n",
    "        edge_angles[i] = math.atan2( edges[i,1], edges[i,0] )\n",
    "    #print \"Edge angles: \\n\", edge_angles\n",
    "\n",
    "    # Check for angles in 1st quadrant\n",
    "    for i in range( len(edge_angles) ):\n",
    "        edge_angles[i] = abs( edge_angles[i] % (math.pi/2) ) # want strictly positive answers\n",
    "    #print \"Edge angles in 1st Quadrant: \\n\", edge_angles\n",
    "\n",
    "    # Remove duplicate angles\n",
    "    edge_angles = np.unique(edge_angles)\n",
    "    #print \"Unique edge angles: \\n\", edge_angles\n",
    "\n",
    "    # Test each angle to find bounding box with smallest area\n",
    "    min_bbox = (0, sys.maxsize, 0, 0, 0, 0, 0, 0) # rot_angle, area, width, height, min_x, max_x, min_y, max_y\n",
    "    # print \"Testing\", len(edge_angles), \"possible rotations for bounding box... \\n\"\n",
    "    for i in range( len(edge_angles) ):\n",
    "\n",
    "        # Create rotation matrix to shift points to baseline\n",
    "        # R = [ cos(theta)      , cos(theta-PI/2)\n",
    "        #       cos(theta+PI/2) , cos(theta)     ]\n",
    "        R = np.array([ [ math.cos(edge_angles[i]), math.cos(edge_angles[i]-(math.pi/2)) ], [ math.cos(edge_angles[i]+(math.pi/2)), math.cos(edge_angles[i]) ] ])\n",
    "        #print \"Rotation matrix for \", edge_angles[i], \" is \\n\", R\n",
    "\n",
    "        # Apply this rotation to convex hull points\n",
    "        rot_points = np.dot(R, np.transpose(hull_points_2d) ) # 2x2 * 2xn\n",
    "        #print \"Rotated hull points are \\n\", rot_points\n",
    "\n",
    "        # Find min/max x,y points\n",
    "        min_x = np.nanmin(rot_points[0], axis=0)\n",
    "        max_x = np.nanmax(rot_points[0], axis=0)\n",
    "        min_y = np.nanmin(rot_points[1], axis=0)\n",
    "        max_y = np.nanmax(rot_points[1], axis=0)\n",
    "        #print \"Min x:\", min_x, \" Max x: \", max_x, \"   Min y:\", min_y, \" Max y: \", max_y\n",
    "\n",
    "        # Calculate height/width/area of this bounding rectangle\n",
    "        width = max_x - min_x\n",
    "        height = max_y - min_y\n",
    "        area = width*height\n",
    "        #print \"Potential bounding box \", i, \":  width: \", width, \" height: \", height, \"  area: \", area \n",
    "\n",
    "        # Store the smallest rect found first (a simple convex hull might have 2 answers with same area)\n",
    "        if (area < min_bbox[1]):\n",
    "            min_bbox = ( edge_angles[i], area, width, height, min_x, max_x, min_y, max_y )\n",
    "        # Bypass, return the last found rect\n",
    "        #min_bbox = ( edge_angles[i], area, width, height, min_x, max_x, min_y, max_y )\n",
    "\n",
    "    # Re-create rotation matrix for smallest rect\n",
    "    angle = min_bbox[0]   \n",
    "    R = np.array([ [ math.cos(angle), math.cos(angle-(math.pi/2)) ], [ math.cos(angle+(math.pi/2)), math.cos(angle) ] ])\n",
    "    #print \"Projection matrix: \\n\", R\n",
    "\n",
    "    # Project convex hull points onto rotated frame\n",
    "    proj_points = np.dot(R, np.transpose(hull_points_2d) ) # 2x2 * 2xn\n",
    "    #print \"Project hull points are \\n\", proj_points\n",
    "\n",
    "    # min/max x,y points are against baseline\n",
    "    min_x = min_bbox[4]\n",
    "    max_x = min_bbox[5]\n",
    "    min_y = min_bbox[6]\n",
    "    max_y = min_bbox[7]\n",
    "    #print \"Min x:\", min_x, \" Max x: \", max_x, \"   Min y:\", min_y, \" Max y: \", max_y\n",
    "\n",
    "    # Calculate center point and project onto rotated frame\n",
    "    center_x = (min_x + max_x)/2\n",
    "    center_y = (min_y + max_y)/2\n",
    "    center_point = np.dot( [ center_x, center_y ], R )\n",
    "    #print \"Bounding box center point: \\n\", center_point\n",
    "\n",
    "    # Calculate corner points and project onto rotated frame\n",
    "    corner_points = np.zeros( (4,2) ) # empty 2 column array\n",
    "    corner_points[0] = np.dot( [ max_x, min_y ], R )\n",
    "    corner_points[1] = np.dot( [ min_x, min_y ], R )\n",
    "    corner_points[2] = np.dot( [ min_x, max_y ], R )\n",
    "    corner_points[3] = np.dot( [ max_x, max_y ], R )\n",
    "    #print \"Bounding box corner points: \\n\", corner_points\n",
    "           \n",
    "    return corner_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for visualization of the algorithm output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manifold= toManifoldList(result[result['cluster'] == 2])\n",
    "trace = []\n",
    "trace.append(go.Scatter3d(\n",
    "x=np.array(manifold[:,0]),\n",
    "y=np.array(manifold[:,1]),\n",
    "z=np.array(manifold[:,2]),\n",
    "mode='markers',\n",
    "marker=dict(size=4, line=dict(width=0.5), opacity=0.8),\n",
    "name= 0,\n",
    "text = [0],\n",
    "textposition='bottom center'))\n",
    "          \n",
    "projection= np.array(plane((result[result['cluster'] == 2])))\n",
    "trace.append(go.Scatter3d(\n",
    "x=np.array(projection[:,0]),\n",
    "y=np.array(projection[:,1]),\n",
    "z=np.array(projection[:,2]),\n",
    "mode='markers',\n",
    "marker=dict(size=4, line=dict(width=0.5), opacity=0.8),\n",
    "name= 1,\n",
    "text = [1],\n",
    "textposition='bottom center'))\n",
    "     \n",
    "\n",
    "data_test3 = go.Data(trace)\n",
    "\n",
    "# Dictionary of style options for all axes\n",
    "axis = dict(\n",
    "    showbackground=True, # show axis background\n",
    "    backgroundcolor=\"rgb(204, 204, 204)\", # set background color to grey\n",
    "    gridcolor=\"rgb(255, 255, 255)\",       # set grid line color\n",
    "    zerolinecolor=\"rgb(255, 255, 255)\",   # set zero grid line color\n",
    ")\n",
    "\n",
    "# Make a layout object\n",
    "layout = go.Layout(showlegend=True,\n",
    "    title='Manifold', # set plot title\n",
    "    scene=go.Scene(  # axes are part of a 'scene' in 3d plots\n",
    "        xaxis=go.XAxis(axis), # set x-axis style\n",
    "        yaxis=go.YAxis(axis), # set y-axis style\n",
    "        zaxis=go.ZAxis(axis)),  # set z-axis style\n",
    "\n",
    ")\n",
    "\n",
    "# Make a figure object\n",
    "fig = go.Figure(data=data_test3, layout=layout)\n",
    "iplot(fig, filename='test3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second example (the indexing commands in the function definitions for toManifoldList and toManifoldDF are slightly altered to cater to the raw data used in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data= pd.DataFrame({'0': result['Avg movement magnitude normalised'], '1': result['Total movement magnitude normalised'], '2': result['Total time normalised']})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toManifoldList(result):\n",
    "    L= []\n",
    "    array= np.array([result['0'], result['1'], result['2']])\n",
    "    size= array[0].size\n",
    "    for i in range(size):\n",
    "        x= array[0][i]\n",
    "        y= array[1][i]\n",
    "        z= array[2][i]\n",
    "        L.append([x, y, z])\n",
    "        \n",
    "    return np.array(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toManifoldDF(result):\n",
    "    return pd.DataFrame({'x': result['0'], 'y': result['1'], 'z': result['2']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace= []\n",
    "\n",
    "manifold= toManifoldList(data)\n",
    "trace.append(go.Scatter3d(\n",
    "x=np.array(manifold[:,0]),\n",
    "y=np.array(manifold[:,1]),\n",
    "z=np.array(manifold[:,2]),\n",
    "mode='markers',\n",
    "marker=dict(size=4, line=dict(width=0.5), opacity=0.8),\n",
    "name= 1,\n",
    "text = [1],\n",
    "textposition='bottom center'))\n",
    "\n",
    "print(type(data))\n",
    "plane1= plane(data)\n",
    "trace.append(go.Scatter3d(\n",
    "x=np.array(plane1[:,0]),\n",
    "y=np.array(plane1[:,1]),\n",
    "z=np.array(plane1[:,2]),\n",
    "mode='markers',\n",
    "marker=dict(size=4, line=dict(width=0.5), opacity=0.8),\n",
    "name= 1,\n",
    "text = [1],\n",
    "textposition='bottom center'))\n",
    "\n",
    "\n",
    "data_test3 = go.Data(trace)\n",
    "\n",
    "# Dictionary of style options for all axes\n",
    "axis = dict(\n",
    "    showbackground=True, # show axis background\n",
    "    backgroundcolor=\"rgb(204, 204, 204)\", # set background color to grey\n",
    "    gridcolor=\"rgb(255, 255, 255)\",       # set grid line color\n",
    "    zerolinecolor=\"rgb(255, 255, 255)\",   # set zero grid line color\n",
    ")\n",
    "\n",
    "# Make a layout object\n",
    "layout = go.Layout(showlegend=True,\n",
    "    title='Manifold', # set plot title\n",
    "    scene=go.Scene(  # axes are part of a 'scene' in 3d plots\n",
    "        xaxis=go.XAxis(axis), # set x-axis style\n",
    "        yaxis=go.YAxis(axis), # set y-axis style\n",
    "        zaxis=go.ZAxis(axis)),  # set z-axis style\n",
    "\n",
    ")\n",
    "\n",
    "# Make a figure object\n",
    "fig = go.Figure(data=data_test3, layout=layout)\n",
    "iplot(fig, filename='test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
